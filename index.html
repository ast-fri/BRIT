<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>BRIT: Bidirectional Retrieval over Unified Image-Text Graph</title>
  <meta name="description" content="A multi-modal RAG framework for enterprise-specific proprietary documents without fine-tuning">
  <meta name="keywords" content="MLLM, RAG, multi-modal retrieval, document AI, enterprise documents, text-image graph, BRIT">
  <meta name="author" content="Ainulla Khan, Yamada Moyuru, Srinidhi Akella">  
  <style>
    :root {
      --primary-bg: #f8fafc;
      --container-bg: #ffffff;
      --fancy-shadow: 0 12px 36px 0 rgba(51,65,85,0.12);
      --section-shadow: 0 4px 24px 0 rgba(71,85,105,0.08), 0 1.5px 5px 0 #e2e8f0;
      --header-main: #1e293b;
      --accent: linear-gradient(90deg, #334155 0%, #475569 100%);
      --border: #cbd5e1;
      --badge-bg: #475569;
      --author-bg: #f1f5f9;
      --author-highlight: #64748b;
      --gradient-light: linear-gradient(120deg, #ffffff 40%, #f8fafc 100%);
      --subtle: #64748b;
      --section-bg: #fcfcfd;
      --blue-table: #f1f5f9;
    }
    body {
      margin: 0;
      background: var(--primary-bg);
      font-family: 'Segoe UI', 'Montserrat', Tahoma, Geneva, Verdana, sans-serif;
      color: #334155;
      line-height: 1.8;
    }
    .container {
      max-width: 1100px;
      margin: 42px auto;
      padding: 37px 24px 44px 24px;
      background: var(--container-bg);
      border-radius: 22px;
      box-shadow: var(--fancy-shadow);
    }
    .header {
      text-align: center;
      margin-bottom: 28px;
      padding-top: 6px;
    }
    .header h1 {
      font-size: 2.5rem;
      font-weight: 800;
      letter-spacing: -1.2px;
      margin: 2px 0 8px;
      color: var(--header-main);
      line-height: 1.1;
      background: var(--accent);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
    } 
    .header h2 {
      font-size: 1.0rem;
      font-weight: 500;
      color: #475569;
      margin-bottom: 22px;
      letter-spacing: 0.03em;
      opacity: 0.84;
    }
    .author-list-formal {
      margin: 9px 0 6px 0;
      display: flex;
      flex-direction: column;
      align-items: center;
      gap: 0;
      font-family: 'Times New Roman', serif;
      color: #1e293b;
      font-weight: 400;
      font-size: 1.0rem;
    }
    .author-names {
      background: var(--author-bg);
      padding: 9px 19px;
      border-radius: 7.5px;
      box-shadow: 0 2.3px 9px #e2e8f0;
      font-size: 1.0rem;
      font-weight: 500;
      margin-bottom: 2px;
    }
    .author-names .sup {
      font-size: 0.85em;
      color: var(--author-highlight);
      vertical-align: super;
    }
    .affiliations {
      font-size: 1.0rem;
      color: #64748b;
      background: none;
      margin-bottom: 1.5px;
      text-align: center;
    }
    .author-footnote {
      font-size: 0.8rem;
      color: #64748b;
      margin: 0 0 13px;
      text-align: center;
    }
    .links-section {
      display: flex;
      justify-content: center;
      gap: 16px;
      margin: 12px 0 34px 0;
      flex-wrap: wrap;
    }
    .link-button {
      display: inline-flex;
      align-items: center;
      gap: 7px;
      background: var(--badge-bg);
      color: #fff;
      text-decoration: none;
      padding: 10px 22px;
      border-radius: 26px;
      font-size: 1.05rem;
      font-weight: 600;
      transition: background 0.17s;
      box-shadow: 0 2px 8px rgba(71,85,105,0.15);
      background-image: linear-gradient(105deg, #475569 0%, #334155 100%);
    }
    .link-button.github { background-image: linear-gradient(90deg, #374151 0%, #4b5563 100%); }
    .link-button.huggingface { background: #6b7280; }
    .link-button.arxiv { background: #991b1b; }
    .link-button:hover { background: #374151; }
    .table-of-contents {
      background: var(--gradient-light);
      border: 1.6px solid var(--border);
      border-radius: 14px;
      padding: 22px 18px 20px 24px;
      margin-bottom: 38px;
      box-shadow: 0 1.2px 7px #e2e8f0;
    }
    .table-of-contents h3 {
      margin-top: 0;
      font-size: 1.14rem;
      color: #475569;
      text-transform: uppercase;
      letter-spacing: 0.055em;
    }
    .table-of-contents ul {
      list-style: none;
      padding-left: 0;
      margin: 0;
    }
    .table-of-contents li {
      margin: 7.5px 0;
      font-size: 1.03rem;
    }
    .table-of-contents a {
      color: #64748b;
      text-decoration: none;
      font-weight: 600;
      border-bottom: 1.2px dotted #94a3b8;
    }
    .table-of-contents a:hover {
      text-decoration: underline;
      color: #475569;
    }
    .section {
      background: var(--section-bg);
      border: 1.2px solid #e2e8f0;
      border-radius: 13px;
      padding: 35px 31px 24px 31px;
      margin-bottom: 44px;
      box-shadow: var(--section-shadow);
    }
    .section-title {
      font-size: 1.44rem;
      font-weight: 800;
      background: var(--accent);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      margin-bottom: 20px;
      border-bottom: 1.8px solid #cbd5e1;
      display: block;
      padding-bottom: 11px;
      font-family: 'Montserrat', 'Segoe UI', sans-serif;
      letter-spacing: 0.01em;
    }
    p, li, ul {
      font-size: 1.07rem;
      color: #334155;
      margin-bottom: 7px;
    }
    .abstract {
      font-size: 1.11rem;
      color: #1e293b;
      text-align:justify;
      background: #f8fafc;
      border-radius: 7px;
      padding: 12px 13px;
      margin-bottom: 0;
      box-shadow: 0 1.6px 9px #e2e8f0;
    }
    .highlight-box {
      background: linear-gradient(115deg, #f8fafc 40%, #f1f5f9 100%);
      color: #1e293b;
      border-radius: 12px;
      padding: 18px 22px 15px 18px;
      border-left: 6px solid #64748b;
      margin: 25px 2px 23px 2px;
      box-shadow: 0 1px 5px #cbd5e1;
    }
    .highlight-box h3 {
      margin: 0 0 8px 0;
      color: #475569;
      font-size: 1.07rem;
      font-weight: 700;
    }
    .architecture-diagram {
      display: flex;
      flex-direction: column;
      align-items: center;
      gap: 20px;
      margin: 25px 0;
      padding: 20px;
      background:  #fff;
      border-radius: 16px;
      box-shadow: 0 6px 24px rgba(51,65,85,0.08);
      border: 1px solid #e2e8f0;
      width: 80%;
    }
    .architecture-diagram img {
      max-width: 100%;
      max-height: 800px; /* Adjust this value based on your needs */
      height: auto;
      width: auto;
      object-fit: contain;
      border-radius: 8px;
    }
    .flow-step {
      display: flex;
      align-items: center;
      gap: 15px;
      padding: 15px 20px;
      background: #fff;
      border-radius: 10px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
      width: 100%;
      max-width: 600px;
    }
    .step-number {
      background: var(--accent);
      color: white;
      width: 40px;
      height: 40px;
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
      font-weight: bold;
      flex-shrink: 0;
    }
    .step-content {
      flex: 1;
    }
    .step-title {
      font-weight: 700;
      font-size: 1.1rem;
      color: #475569;
      margin: 0 0 5px 0;
    }
    .step-description {
      font-size: 1rem;
      color: #334155;
      margin: 0;
    }
    .example-showcase {
      display: flex;
      flex-direction: column;
      gap: 40px;
      margin: 25px 0;
    }
    .example-item {
      display: flex;
      gap: 30px;
      align-items: flex-start;
      background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);
      border-radius: 16px;
      padding: 25px;
      box-shadow: 0 6px 24px rgba(51,65,85,0.08);
      border: 1px solid #e2e8f0;
    }
    .example-item:nth-child(even) {
      flex-direction: row-reverse;
    }
    .example-item img {
      flex: 1;
      max-width: 500px;
      min-width: 300px;
      border-radius: 12px;
      box-shadow: 0 8px 32px rgba(51,65,85,0.12);
      background: #fff;
      border: 2px solid #cbd5e1;
      transition: transform 0.2s, box-shadow 0.2s;
    }
    .example-item img:hover {
      transform: scale(1.02);
      box-shadow: 0 12px 48px rgba(51,65,85,0.18);
    }
    .example-description {
      flex: 1;
      min-width: 280px;
      padding: 10px 15px; 
    }
    .example-description h4 {
      font-size: 1.0rem;
      color: #374151;
    }
    .example-description p {
      font-size: 1.08rem;
      color: #334155;
      line-height: 1.7;
      margin: 0;
      text-align: justify;
    }

    .results-table {
      width: 100%;
      border-collapse: collapse;
      margin: 17px 0 10px 0;
      background: var(--blue-table);
      border-radius: 8px;
      overflow: hidden;
      font-size: 1.05rem;
    }
    .results-table th, .results-table td {
      border: 1.2px solid #cbd5e1;
      padding: 11px 19px;
      text-align: left;
    }
    .results-table th {
      background: #e2e8f0;
      font-weight: 750;
      color: #374151;
    }
    .results-table tr:nth-child(even) { background: #f8fafc; }
    .footer {
      text-align: center;
      font-size: 1rem;
      color: #64748b;
      margin-top: 45px;
      padding: 23px 0 8px 0;
      background: transparent;
    }
    .comparison-diagram {
      max-width: 100%;
      margin: 20px auto;
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      background: #ffffff;
      padding: 20px;
      border-radius: 12px;
      box-shadow: 0 4px 16px rgba(0,0,0,0.1);
    }
    
    .method-row {
      display: flex;
      align-items: center;
      margin-bottom: 40px;
      padding: 20px;
      border-radius: 10px;
      background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);
      border: 1px solid #e2e8f0;
    }
    
    .method-title-diagram {
      font-size: 1.1rem;
      font-weight: 700;
      color: #475569;
      margin-bottom: 10px;
    }
    
    .step {
      flex: 1;
      text-align: center;
      position: relative;
      padding: 0 10px;
    }
    
    .step:not(:last-child)::after {
      content: '→';
      position: absolute;
      right: -15px;
      top: 50%;
      transform: translateY(-50%);
      font-size: 1.5rem;
      color: #666;
      font-weight: bold;
    }
    
    .document-icon {
      width: 80px;
      height: 60px;
      background: #f8fafc;
      border: 2px solid #cbd5e1;
      border-radius: 4px;
      margin: 0 auto 10px;
      position: relative;
      display: flex;
      align-items: center;
      justify-content: center;
    }
    
    .document-icon::before {
      content: '';
      width: 60%;
      height: 8px;
      background: linear-gradient(90deg, #94a3b8 0%, #94a3b8 70%, transparent 70%);
      background-size: 12px 2px;
      background-repeat: repeat-x;
      position: absolute;
      top: 15px;
    }
    
    .document-icon::after {
      content: '';
      width: 40%;
      height: 8px;
      background: linear-gradient(90deg, #94a3b8 0%, #94a3b8 70%, transparent 70%);
      background-size: 8px 2px;
      background-repeat: repeat-x;
      position: absolute;
      top: 35px;
    }
    
    .chunks-box {
      width: 70px;
      height: 80px;
      background: #f1f5f9;
      border: 2px solid #cbd5e1;
      border-radius: 6px;
      margin: 0 auto 10px;
      position: relative;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      gap: 4px;
    }
    
    .chunk-item {
      width: 50px;
      height: 8px;
      background: #94a3b8;
      border-radius: 2px;
    }
    
    .pages-box {
      width: 70px;
      height: 80px;
      background: #f8fafc;
      border: 2px solid #e2e8f0;
      border-radius: 6px;
      margin: 0 auto 10px;
      position: relative;
      display: flex;
      align-items: center;
      justify-content: center;
    }
    
    .pages-box::before {
      content: '';
      width: 40px;
      height: 50px;
      background: #fff;
      border: 1px solid #cbd5e1;
      position: absolute;
      border-radius: 2px;
    }
    
    .graph-box {
      width: 90px;
      height: 80px;
      background: #f1f5f9;
      border: 2px solid #94a3b8;
      border-radius: 6px;
      margin: 0 auto 10px;
      position: relative;
      display: flex;
      align-items: center;
      justify-content: center;
    }
    
    .graph-nodes {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 8px;
      align-items: center;
    }
    
    .node {
      width: 12px;
      height: 12px;
      border-radius: 50%;
      position: relative;
    }
    
    .text-node {
      background: #64748b;
    }
    
    .image-node {
      background: #475569;
    }
    
    .node-connection {
      position: absolute;
      width: 2px;
      height: 16px;
      background: #94a3b8;
      top: 6px;
      right: -5px;
    }
    
    .query-box {
      width: 100px;
      height: 30px;
      background: linear-gradient(135deg, #64748b 0%, #475569 100%);
      color: white;
      border-radius: 15px;
      margin: 0 auto 10px;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 0.8rem;
      font-weight: 600;
    }
    
    .step-label {
      font-size: 0.9rem;
      font-weight: 600;
      color: #64748b;
      margin-bottom: 5px;
    }
    
    .problems-list {
      flex: 0 0 300px;
      margin-left: 20px;
      padding-left: 20px;
      border-left: 3px solid #fecaca;
      background: #fef2f2;
      padding: 15px;
      border-radius: 8px;
    }
    
    .problem-item {
      display: flex;
      align-items: flex-start;
      margin-bottom: 12px;
      font-size: 0.9rem;
      color: #dc2626;
    }
    
    .problem-item::before {
      content: '✗';
      color: #ef4444;
      font-weight: bold;
      margin-right: 8px;
      margin-top: 1px;
    }
    
    .benefits-list {
      flex: 0 0 300px;
      margin-left: 20px;
      padding-left: 20px;
      border-left: 3px solid #bbf7d0;
      background: #f0fdf4;
      padding: 15px;
      border-radius: 8px;
    }
    
    .benefit-item {
      display: flex;
      align-items: flex-start;
      margin-bottom: 12px;
      font-size: 0.9rem;
      color: #166534;
    }
    
    .benefit-item::before {
      content: '✓';
      color: #22c55e;
      font-weight: bold;
      margin-right: 8px;
      margin-top: 1px;
    }
    
    .enhanced-graph {
      width: 90px;
      height: 80px;
      background: linear-gradient(135deg, #f0fdf4 0%, #bbf7d0 100%);
      border: 2px solid #22c55e;
      border-radius: 6px;
      margin: 0 auto 10px;
      display: flex;
      align-items: center;
      justify-content: center;
      position: relative;
    }
    
    .enhanced-graph::after {
      content: 'Txt ↔ Img';
      position: absolute;
      bottom: 1px;
      left: 42%;
      transform: translateX(-50%);
      font-size: 0.7rem;
      color: #22c55e;
      font-weight: 600;
    }
    
    .chunk-wise .method-title-diagram {
      color: #dc2626;
    }
    
    .page-wise .method-title-diagram {
      color: #ea580c;
    }
    
    .brit-method .method-title-diagram {
      color: #16a34a;
    }
    @media (max-width: 850px) {
      .container { padding: 8px 3px 17px 7px; }
      .section { padding: 16px 6px 13px 8px; }
      .table-of-contents { padding: 17px 7px 16px 15px; }
      .header h1 { font-size: 1.52rem;}
      .results-table th, .results-table td { padding: 8px 12px; }
      .flow-step {
        flex-direction: column;
        text-align: center;
        gap: 10px;
      }

      .method-row {
        flex-direction: column;
      }
      
      .step {
        margin-bottom: 20px;
      }
      
      .step:not(:last-child)::after {
        content: '↓';
        right: 50%;
        top: auto;
        bottom: -15px;
        transform: translateX(50%);
      }
      
      .problems-list, .benefits-list {
        flex: none;
        margin-left: 0;
        margin-top: 20px;
        border-left: none;
        border-top: 3px solid #fed7d7;
        padding-left: 15px;
      }
      
      .benefits-list {
        border-top-color: #c6f6d5;
      }
    }
  </style>
</head>
<body>
  <div class="container">
    <header class="header">
      <h1>BRIT: Bidirectional Retrieval over Unified Image-Text Graph</h1>
      <h2>A multi-modal RAG framework for enterprise-specific proprietary documents without fine-tuning</h2>
      <div class="author-list-formal">
        <div class="author-names">
          Ainulla Khan<span class="sup">&#42;</span>,
          Yamada Moyuru<span class="sup">&#42;</span>,
          Srinidhi Akella<span class="sup"></span>
        </div>
        <div class="affiliations">
          <span class="sup"></span>Fujitsu Research India
        </div>
        <div class="author-footnote">
          <span class="sup">&#42;</span>Equal contribution &nbsp;&nbsp;
        </div>
      </div>
      <div class="links-section">
        <a href="https://github.com/MMRAG-FRI/mm-rag" class="link-button github"><span>📄</span> GitHub</a>
        <a href="https://huggingface.co/datasets/ainulla/mmrag" class="link-button huggingface"><span>🤗</span> Hugging Face</a>
        <a href="https://arxiv.org/abs/2505.18450" class="link-button arxiv"><span>📚</span> Paper </a>
      </div>
    </header>

    <div class="table-of-contents">
      <h3>Table of Contents</h3>
      <ul>
        <li><a href="#abstract">Abstract</a></li>
        <li><a href="#introduction">Introduction</a></li>
        <li><a href="#architecture">BRIT Architecture</a></li>
        <li><a href="#multimodal-graph">MM-RAG Benchmark</a></li>
        <li><a href="#pcst-retrieval">Qualitative Examples</a></li>
        <li><a href="#results">Results & Analysis</a></li>

      </ul>
    </div>

    <section class="section" id="abstract">
      <span class="section-title">Abstract</span>
      <p class="abstract">
        Enterprise documents containing proprietary terminology and company-specific names often cause traditional embedding-based RAG systems to fail due to poor similarity matching with pre-trained models. <strong>BRIT</strong> addresses this challenge through a novel multi-modal RAG framework that constructs unified text-image graphs from documents and retrieves query-relevant subgraphs without requiring fine-tuning. By capturing both semantic and spatial relationships between textual and visual elements, BRIT enables effective cross-modal retrieval on enterprise-specific content. We introduce the <strong>MM-RAG</strong> test set to evaluate multi-modal question answering capabilities that require understanding complex text-image relationships.
      </p>
    </section>

    <section class="section" id="introduction">
      <span class="section-title">Introduction</span>
      <div class="comparison-diagram">
        <!-- Chunk-wise Retrieval -->
        <div class="method-row chunk-wise">
          <div class="step">
            <div class="document-icon"></div>
            <div class="step-label">Documents</div>
          </div>
          
          <div class="step">
            <div class="chunks-box">
              <div class="chunk-item"></div>
              <div class="chunk-item"></div>
              <div class="chunk-item"></div>
              <div class="chunk-item"></div>
            </div>
            <div class="step-label">Extract chunks</div>
          </div>
          
          
          <div class="step">
            <div class="chunks-box">
              <div class="chunk-item" style="background: #4299e1;"></div>
              <div class="chunk-item" style="background: #4299e1;"></div>
            </div>
            <div class="step-label">Similarity-based chunk retrieval</div>
          </div>
          
          <div class="problems-list">
            <div class="method-title-diagram">(a) Chunk-wise retrieval</div>
            <div class="problem-item">Lose relations between chunks</div>
            <div class="problem-item">Miss contents that cannot be identified directly from the query</div>
          </div>
        </div>
        
        <!-- Page-wise Retrieval -->
        <div class="method-row page-wise">
          <div class="step">
            <div class="document-icon"></div>
            <div class="step-label">Documents</div>
          </div>
          
          <div class="step">
            <div class="pages-box"></div>
            <div class="step-label">Convert pages into images</div>
          </div>
          
          <div class="step">
            <div class="pages-box" style="background: #e6fffa;"></div>
            <div class="step-label">Similarity-based page retrieval</div>
          </div>
          
          <div class="problems-list">
            <div class="method-title-diagram">(b) Page-wise retrieval</div>
            <div class="problem-item">Lose relations across pages</div>
            <div class="problem-item">Miss contents that cannot be identified directly from the query</div>
          </div>
        </div>
        
        <!-- BRIT Method -->
        <div class="method-row brit-method">
          <div class="step">
            <div class="document-icon"></div>
            <div class="step-label">Documents</div>
          </div>
          
          <div class="step">
            <div class="graph-box">
              <div class="graph-nodes">
                <div class="node text-node">
                  <div class="node-connection"></div>
                </div>
                <div class="node image-node"></div>
                <div class="node image-node">
                  <div class="node-connection"></div>
                </div>
                <div class="node text-node"></div>
              </div>
            </div>
            <div class="step-label">Construct a graph</div>
          </div>
    
          <div class="step">
            <div class="enhanced-graph">
              <div class="graph-nodes">
                <div class="node text-node" style="background: #38b2ac;"></div>
                <div class="node image-node" style="background: #38b2ac;"></div>
              </div>
            </div>
            <div class="step-label">Bidirectional linked-context retrieval</div>
          </div>
          
          <div class="benefits-list">
            <div class="method-title-diagram">(c) BRIT (Ours)</div>
            <div class="benefit-item">Preserves multi-modal relationships</div>
            <div class="benefit-item">Cross-modal retrieval capability</div>
          </div>
        </div>
      </div>
      
      <div class="highlight-box">
        <h3>Why BRIT matters for Enterprises</h3>
        BRIT's graph-based approach eliminates the need for document-specific fine-tuning while enabling sophisticated cross-modal retrieval.
      </div>
    </section>

    <section class="section" id="architecture">
      <span class="section-title">BRIT Architecture Overview</span>
      <div class="architecture-diagram">
        <img src="images/architecture.png" alt="architecture">
        </div>
      <div class="flow-step">
        <div class="step-number">1</div>
        <div class="step-content">
          <div class="step-title">Document Processing</div>
          <div class="step-description">Extract text and images from multi-modal documents, maintaining spatial and semantic relationships</div>
        </div>
      </div>
      <div class="flow-step">
        <div class="step-number">2</div>
        <div class="step-content">
          <div class="step-title">Graph Construction</div>
          <div class="step-description">Build unified text-image graph while linking textual nodes and images based on the captions, text-image similarity scores and document layout</div>
        </div>
      </div>
      <div class="flow-step">
        <div class="step-number">3</div>
        <div class="step-content">
          <div class="step-title">Query-relevant Sub-graph Retrieval</div>
          <div class="step-description"> Use Prize-Collecting Steiner Tree (PCST) optimization to retrieve query-relevant multi-modal subgraphs, where relevance is determined by computing cosine similarity scores between each node and the input query.</div>
        </div>
      </div>
      <div class="flow-step">
        <div class="step-number">4</div>
        <div class="step-content">
          <div class="step-title">Response Generation</div>
          <div class="step-description">Generate answers using retrieved text-image context</div>
        </div>
      </div>
    </section>

    <section class="section" id="multimodal-graph">
      <span class="section-title">MM-RAG Benchmark</span>
      <p>
        We introduce a <strong>MM-RAG benchmark</strong> comprising <strong>500</strong> complex questions that necessitate cross-modal, multi-hop retrieval to identify the key information.
        The benchmark contains three types of questions:
      </p>
      <ul>
        <li><b>Text-Image questions</b>: Questions requiring a relevant image for answering but that image cannot be directly identified by the question </li>
        <li><b>Image-Text questions</b>: Questions requiring a relevant texts for answering but texts cannot be directly identified by the question</li>
        <li><b>Image-Image questions</b>: Simple baseline questions which can be answered directly based on the images</li>
        <div class="architecture-diagram">
        <img src="images/question_types_desc.png" alt="question_types_desc">
        </div>
      </ul>
    </section>

    <section class="section" id="pcst-retrieval">
      <span class="section-title">Qualitative Examples</span>
      <div class="example-showcase">
        <div class="example-item">
          <img src="images/example-1.jpg" alt="example-1">
          <div class="example-description">
            <h4>Text-Image Question</h4>
            <p> The baseline retrieves similar images matched with the query, however a correct image cannot be retrieved. BRIT can find the query-relevant texts and then retrieve the connected images to reach the answer.</p>
          </div>
        </div>
        
        <div class="example-item">
          <img src="images/example-2.jpg" alt="example-2">
          <div class="example-description">
            <h4>Image-Text Question</h4>
            <p>Both the baseline and BRIT retrieve the relevant image, however the baseline cannot find the relevant texts because an important keyword 'Irene Dalton' is not in the question. Our BRIT finds the relevant image first, then discovers relevant texts by following the link between the image and the text.</p>
          </div>
        </div>
      </div>
    </section>


    <section class="section" id="results">
      <span class="section-title">Results & Analysis</span>
      <p>
       BRIT outperforms the baselines in overall QA accuracy on complex question:
        <ul>
        <li>Image-Image questions are the simple question which does not require the crossmodal multi-hop retrieval. Thus, the baseline methods with the simple retrieval of the top-2 most relevant images achieves the highest accuracy, while BRIT only retrieve 1 image with the similarity.</li>
        <li>The baseline struggles with Image-Text questions, resulting in a large drop in performance compared to other cases.</li>
      </ul>
      </p>
      <table class="results-table">
        <tr>
          <th>Method</th>
          <th>Image-Image (%)</th>
          <th>Text-Image (%)</th>
          <th>Image-Text (%)</th>
        </tr>
        <tr>
          <td>CLIP</td>
          <td>0.81</td>
          <td>0.70</td>
          <td>0.76</td>
        </tr>
        <tr>
          <td>BLIP</td>
          <td><b>0.82</b></td>
          <td>0.68</td>
          <td>0.78</td>
        </tr>

        <tr style="background:#ecfdf5;">
          <td><b>BRIT (Ours)</b></td>
          <td>0.81</td>
          <td><b>0.89</b></td>
          <td><b>0.81</b></td>
      
        </tr>
      </table>
    </section>
    <div class="footer">
      © 2025 Research Project | BRIT: Bidirectional Retrieval over Unified Image-Text Graph
    </div>
  </div>
</body>
</html>